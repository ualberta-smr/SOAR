number of word types: 1494, number of word types w/ frequency >= 1: 1494
/home/mohayemin/anaconda3/envs/SOAR/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
/home/mohayemin/anaconda3/envs/SOAR/lib/python3.8/site-packages/torch/nn/init.py:388: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/home/mohayemin/anaconda3/envs/SOAR/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448216815/work/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
[info] [2021-08-11 14:26:12.093749] Success!
[info] [2021-08-11 14:26:12.094284] Avg Rank 1.4772727272727273
[info] [2021-08-11 14:26:12.163243] Synthesis time: 282.39663648605347
[info] [2021-08-11 14:26:12.163414] self.before_0 = lambda x: x.permute(0,3,1,2)
[info] [2021-08-11 14:26:12.163414] self.var51 = torch.nn.Conv2d(3,64,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var52 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_3 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var161 = torch.nn.Conv2d(64,64,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var162 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var166 = torch.nn.MaxPool2d((2,2),stride=(2,2),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.before_7 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var305 = torch.nn.Conv2d(64,128,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var306 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_10 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var573 = torch.nn.Conv2d(128,128,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var574 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var577 = torch.nn.MaxPool2d((2,2),stride=(2,2),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.before_14 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var753 = torch.nn.Conv2d(128,256,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var754 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_17 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var921 = torch.nn.Conv2d(256,256,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var922 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_20 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var1027 = torch.nn.Conv2d(256,256,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var1028 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_23 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var1197 = torch.nn.Conv2d(256,256,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var1198 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var1199 = torch.nn.MaxPool2d((2,2),stride=(2,2),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.before_27 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var1645 = torch.nn.Conv2d(256,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var1646 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_30 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var1772 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.var1773 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_33 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var1906 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var1907 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_36 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var2052 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var2053 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var2058 = torch.nn.MaxPool2d((2,2),stride=(2,2),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.before_40 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var2207 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var2208 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_43 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var2310 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var2311 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_46 = lambda x: x.permute(0,1,3,2)
[info] [2021-08-11 14:26:12.163414] self.var2398 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var2399 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.before_49 = lambda x: x.permute(0,1,2,3)
[info] [2021-08-11 14:26:12.163414] self.var2492 = torch.nn.Conv2d(512,512,(3,3),stride=(1,1),padding=(1,1))
[info] [2021-08-11 14:26:12.163414] self.var2493 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var2505 = torch.nn.MaxPool2d((2,2),stride=(2,2),padding=(0,0))
[info] [2021-08-11 14:26:12.163414] self.before_53 = lambda x: x.permute(0,3,2,1)
[info] [2021-08-11 14:26:12.163414] self.var2526 = lambda x: torch.flatten(x,1)
[info] [2021-08-11 14:26:12.163414] self.var5080 = torch.nn.Linear(18432,4096)
[info] [2021-08-11 14:26:12.163414] self.var5081 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var5533 = torch.nn.Linear(4096,4096)
[info] [2021-08-11 14:26:12.163414] self.var5534 = torch.nn.ReLU()
[info] [2021-08-11 14:26:12.163414] self.var5990 = torch.nn.Linear(4096,1000)
[info] [2021-08-11 14:26:12.163414] self.var5993 = torch.nn.Softmax(dim=-1)
number of word types: 1494, number of word types w/ frequency >= 1: 1494
/home/mohayemin/anaconda3/envs/SOAR/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[info] [2021-08-11 14:26:19.027856] Avg Rank 1.4772727272727273
